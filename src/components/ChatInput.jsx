// src/components/ChatInput.jsx
import React, { useState, useRef, useEffect } from 'react';
import './ChatInput.css';

// Ğ’Ñ‹Ñ‚Ğ°ÑĞºĞ¸Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ· process.env
const OPENAI_API_KEY = process.env.REACT_APP_OPENAI_API_KEY;

const ChatInput = ({ onSend }) => {
  const [text, setText] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const textareaRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  // ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ²Ñ‹ÑĞ¾Ñ‚Ğ°
  useEffect(() => {
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
      textareaRef.current.style.height = Math.min(textareaRef.current.scrollHeight, 200) + 'px';
    }
  }, [text]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mr = new MediaRecorder(stream);
      mediaRecorderRef.current = mr;
      audioChunksRef.current = [];

      mr.ondataavailable = e => {
        if (e.data.size > 0) audioChunksRef.current.push(e.data);
      };

      mr.onstop = async () => {
        const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append('file', blob, 'voice.webm');
        formData.append('model', 'whisper-1');

        try {
          const resp = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: {
              Authorization: `Bearer ${OPENAI_API_KEY}`
            },
            body: formData
          });
          if (!resp.ok) {
            console.error('Whisper API error status:', resp.status);
            return;
          }
          const data = await resp.json();
          if (data.text) setText(data.text);
        } catch (err) {
          console.error('ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ² Whisper:', err);
        }
      };

      mr.start();
      setIsRecording(true);
    } catch (err) {
      console.error('ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ñƒ:', err);
    }
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };

  const handleSend = () => {
    if (text.trim()) {
      onSend(text.trim());
      setText('');
    }
  };

  const handleKeyDown = e => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  return (
    <div className="chat-input">
      <div className="textarea-container">
        <textarea
          ref={textareaRef}
          rows="1"
          value={text}
          onChange={e => setText(e.target.value)}
          onKeyDown={handleKeyDown}
          placeholder="Ğ¡Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚Ğµ Ñ‡Ñ‚Ğ¾-Ğ½Ğ¸Ğ±ÑƒĞ´ÑŒâ€¦"
        />
      </div>

      {isRecording ? (
        <button className="send-btn" onClick={stopRecording} aria-label="Ğ¡Ñ‚Ğ¾Ğ¿ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ">â¹</button>
      ) : text.trim() === '' ? (
        <button className="send-btn" onClick={startRecording} aria-label="Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ">ğŸ¤</button>
      ) : (
        <button className="send-btn" onClick={handleSend} aria-label="ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ">â¬†ï¸</button>
      )}
    </div>
  );
};

export default ChatInput;
